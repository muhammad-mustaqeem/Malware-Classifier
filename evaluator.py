import joblib

import pandas as pd
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, log_loss


class ModelEvaluator:
    """Class to evaluate a saved model on a given dataset."""

    def __init__(self, saved_model_path):
        """
        Initialize the ModelEvaluator object.

        Parameters:
        - saved_model_path (str): Path to the saved model file (e.g., 'saved_model.h5').
        """
        self.saved_model_path = saved_model_path
        self.model = None

    def _load_model(self):
        """Load the saved model."""
        try:
            # Load the model using your preferred method (e.g., TensorFlow, Keras)
            self.model = joblib.load(self.saved_model_path)

        except Exception as e:
            return str(e)

    def _load_dataset(self, test_data_path):
        """
        Load the test dataset from a CSV file.

        Parameters:
        - test_data_path (str): Path to the CSV file containing the test data.

        Returns:
        - DataFrame: The loaded test dataset.
        """
        try:
            test_data = pd.read_csv(test_data_path)
            return test_data
        except Exception as e:
            return str(e)

    def evaluate(self, test_data_path):
        """
        Evaluate the loaded model on the given test dataset.

        Parameters:
        - test_data_path (str): Path to the CSV file containing the test data.

        Returns:
        - dict: A dictionary containing the evaluation metrics. If an exception occurs,
                a dictionary with the 'error' key will be returned.
        """
        metrics = {}

        # Load the model
        load_model_result = self._load_model()
        if load_model_result is not None:
            metrics['error'] = load_model_result
            return metrics

        # Load the test dataset
        test_data = self._load_dataset(test_data_path)
        if isinstance(test_data, str):
            metrics['error'] = test_data
            return metrics

        try:
            # Split the test dataset into features and labels
            X_test = test_data.drop(['Target', 'File Name'], axis=1)
            y_test = test_data['Target']

            # Make predictions using the loaded model
            if isinstance(self.model, CalibratedClassifierCV):
                try:
                    y_pred = self.model.predict_proba(X_test)
                except AttributeError:
                    # For CalibratedClassifierCV, access the base classifier for predictions
                    y_pred = self.model.base_estimator.predict_proba(X_test)
            else:
                y_pred = self.model.predict(X_test)

            # Calculate f1 score
            metrics['f1_score'] = f1_score(y_test, y_pred)

            # Calculate standard deviation
            metrics['standard_deviation'] = y_pred.std()

            # Calculate log loss
            metrics['log_loss'] = log_loss(y_test, y_pred)

            # Calculate accuracy
            metrics['accuracy'] = accuracy_score(y_test, y_pred)

            # Calculate precision
            metrics['precision'] = precision_score(y_test, y_pred)

            # Calculate recall
            metrics['recall'] = recall_score(y_test, y_pred)

            # Calculate confidence (assuming the predictions are probabilities)
            metrics['confidence'] = y_pred.max(axis=1).mean()

        except Exception as e:
            metrics['error'] = str(e)

        return metrics


if __name__ == '__main__':
    eval = ModelEvaluator(saved_model_path='./Models/Light Graient Boosting.sav')
    metrics = eval.evaluate(test_data_path='Feature_Matrix/Feature_Fusion_TEST_Matrix.csv')

    print(metrics)
